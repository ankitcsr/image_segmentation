{"cells":[{"metadata":{"id":"3EJypd5dX841","colab_type":"code","outputId":"afcfabb7-740b-4cc5-a40c-77e55f40883c","colab":{"base_uri":"https://localhost:8080/","height":68},"trusted":true},"cell_type":"code","source":"!curl https://warwick.ac.uk/fac/sci/dcs/research/tia/glascontest/download/warwick_qu_dataset_released_2016_07_08.zip --output warwick_qu_dataset_released_2016_07_08.zip","execution_count":null,"outputs":[]},{"metadata":{"id":"sDOLwy2hYW_6","colab_type":"code","outputId":"1515805a-f39f-4f24-dc27-13ec37100289","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{"id":"KMQjZ5MBYzIW","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"!unzip  warwick_qu_dataset_released_2016_07_08.zip","execution_count":null,"outputs":[]},{"metadata":{"id":"fnj_QEiJY_IN","colab_type":"code","outputId":"e90923d6-4e6e-4c2f-abc2-604f5f38ffd9","colab":{"base_uri":"https://localhost:8080/","height":51},"trusted":true},"cell_type":"code","source":"!ls\n","execution_count":null,"outputs":[]},{"metadata":{"id":"CmX0bAzjZC1N","colab_type":"code","outputId":"760ad3d9-0dcf-4d10-a93d-a540b56ebfdf","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"cd 'Warwick QU Dataset (Released 2016_07_08)'","execution_count":null,"outputs":[]},{"metadata":{"id":"iPS4B01HZMz2","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom PIL import Image\n","execution_count":null,"outputs":[]},{"metadata":{"id":"1OmGw0MiZ-KN","colab_type":"code","outputId":"80bedb04-d6db-4455-bf7a-c3cf1e872406","colab":{"base_uri":"https://localhost:8080/","height":539},"trusted":true},"cell_type":"code","source":"Image.open('train_2.bmp')","execution_count":null,"outputs":[]},{"metadata":{"id":"JUWMP-Pma3cT","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imread,imshow\nfrom PIL import Image\nimport torch\nfrom skimage import io, transform\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv('Grade.csv')\nlen(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"cBufzBhked-P","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"class Train_dataset(Dataset):\n    def __init__(self,csv_path,transform_img):\n        self.data=pd.read_csv(csv_path)\n        self.train_data=self.data[self.data.name.str.match('train*')]\n        self.transform_img=transform_img\n    def __len__(self):\n        return len(self.train_data)\n\n    def __getitem__(self,index):\n        image_name=self.train_data.name.iloc[index]+'.bmp'\n        image=Image.open(image_name)\n        image=self.transform_img(image)\n        label_name=self.train_data[' grade (GlaS)'].iloc[0]\n        label=  1 if label_name == \" malignant\" else 0\n        return [image,label]\n    ","execution_count":null,"outputs":[]},{"metadata":{"id":"8E3Ucsd7qyX-","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"class Valid_dataset(Dataset):\n    def __init__(self,csv_path,transform_img):\n        self.data=pd.read_csv(csv_path)\n        self.train_data=self.data[self.data.name.str.match('testA*')]\n        self.transform_img=transform_img\n    \n    def __len__(self):\n        return len(self.train_data)\n\n    def __getitem__(self, index):\n        image_name=self.train_data.name.iloc[index]+'.bmp'\n        image=Image.open(image_name)\n        image=self.transform_img(image)\n        label_name=self.train_data[' grade (GlaS)'].iloc[0]\n        label=  1 if label_name == \" malignant\" else 0\n        return [image,label]\n    ","execution_count":null,"outputs":[]},{"metadata":{"id":"c0RGXL8Gq0D2","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"class Test_dataset(Dataset):\n    def __init__(self,csv_path,transform_img):\n        self.data=pd.read_csv(csv_path)\n        self.train_data=self.data[self.data.name.str.match('testB*')]\n        self.transform_img=transform_img\n    \n    def __len__(self):\n        return len(self.train_data)\n\n    def __getitem__(self, index):\n        image_name=self.train_data.name.iloc[index]+'.bmp'\n        image=Image.open(image_name)\n        image=self.transform_img(image)\n        label_name=self.train_data[' grade (GlaS)'].iloc[0]\n        label=  1 if label_name == \" malignant\" else 0\n        return [image,label]\n    \n","execution_count":null,"outputs":[]},{"metadata":{"id":"ufyp1OI_tKBt","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"from torchvision import transforms","execution_count":null,"outputs":[]},{"metadata":{"id":"MmKY9lj5tlBl","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"transform_img=transforms.Compose([\n    transforms.Resize((250,250)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.ColorJitter()\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform_test=transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n])","execution_count":null,"outputs":[]},{"metadata":{"id":"eVz1X1Boq5fd","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"train_dataset=Train_dataset('Grade.csv',transform_img)\nvalid_dataset=Valid_dataset('Grade.csv',transform_img)\ntest_dataset=Test_dataset('Grade.csv',transform_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"RtsGjW2EtFxJ","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"params = {'batch_size': 1,'shuffle': True}\nmax_epochs = 10\n\ntraining_generator = DataLoader(train_dataset, **params)\nvalid_generator = DataLoader(valid_dataset, **params)\ntest_generator = DataLoader(test_dataset, **params)","execution_count":null,"outputs":[]},{"metadata":{"id":"d8x-yWSStF3d","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"\n#for local_batch, local_labels in valid_generator:\n        ","execution_count":null,"outputs":[]},{"metadata":{"id":"gTDMmli-kz3V","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"import torchvision.models as models\n","execution_count":null,"outputs":[]},{"metadata":{"id":"3kJDru_hpnG1","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"resnet18 = models.resnet18(pretrained=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn","execution_count":null,"outputs":[]},{"metadata":{"id":"UzYLX0j4pzBA","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"resnet18.fc=nn.Linear(in_features=512, out_features=2, bias=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=resnet18","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=model.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name,param in model.named_parameters():\n    if param.requires_grad == True:\n        print(name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for name,param in list(model.named_parameters())[-8:]:\n#    param.requires_grad = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for name,param in model.named_parameters():\n#    if param.requires_grad == True:\n#        print(name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params_to_update = []\nfor name,param in model.named_parameters():\n    if param.requires_grad == True:\n        params_to_update.append(param)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.optim as optim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nimport copy\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n    since = time.time()\n\n    val_loss_history = []\n    train_loss_history= []\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_loss_so_far = 9999999999\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train','val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n\n            print('{} Loss: {:.4f} '.format(phase, loss))\n\n            # deep copy the model\n            if phase == 'val' and loss < best_loss_so_far:\n                best_loss_so_far=loss\n                best_model_wts = copy.deepcopy(model.state_dict())\n            if phase == 'val':\n                val_loss_history.append(loss)\n            if phase =='train':\n                with torch.no_grad(): \n                    train_loss_history.append(loss)\n                \n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print('Best loss in validation set : {:4f}'.format(best_loss_so_far))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, val_loss_history,train_loss_history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataloaders={'train':training_generator,'val':valid_generator}\noptimizer = optim.Adam(params_to_update,lr=1e-7)\ncriterion = nn.CrossEntropyLoss()\n\nnum_epochs=10\nmodel_classification,v_hist,t_hist=train_model(model, dataloaders, criterion, optimizer, num_epochs=num_epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vhist = []\n\nvhist = [h.cpu().numpy() for h in v_hist]\nthist = []\n\nthist = [h.cpu().detach().numpy() for h in t_hist]\n\nplt.title(\"Loss vs. Number of Training Epochs\")\nplt.xlabel(\"Training Epochs\")\nplt.ylabel(\"Validation Loss\")\nplt.plot(range(1,num_epochs+1),vhist,label=\"Validation loss \")\nplt.plot(range(1,num_epochs+1),thist,label=\"Train loss\")\n\nplt.xticks(np.arange(1, num_epochs+1, 1.0))\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#segmentation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models\n\ndef convrelu(in_channels, out_channels, kernel, padding):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n        nn.ReLU(inplace=True),\n    )\n\n\nclass ResNetUNet(nn.Module):\n    def __init__(self, n_class):\n        super().__init__()\n\n        self.base_model = models.resnet18(pretrained=True)\n        self.base_layers = list(self.base_model.children())\n\n        self.layer0 = nn.Sequential(*self.base_layers[:3]) # size=(N, 64, x.H/2, x.W/2)\n        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n        self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 64, x.H/4, x.W/4)\n        self.layer1_1x1 = convrelu(64, 64, 1, 0)\n        self.layer2 = self.base_layers[5]  # size=(N, 128, x.H/8, x.W/8)\n        self.layer2_1x1 = convrelu(128, 128, 1, 0)\n        self.layer3 = self.base_layers[6]  # size=(N, 256, x.H/16, x.W/16)\n        self.layer3_1x1 = convrelu(256, 256, 1, 0)\n        self.layer4 = self.base_layers[7]  # size=(N, 512, x.H/32, x.W/32)\n        self.layer4_1x1 = convrelu(512, 512, 1, 0)\n\n        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n\n        self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n        self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n        self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n\n        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n\n        self.conv_last = nn.Conv2d(64, n_class, 1)\n\n    def forward(self, input):\n        x_original = self.conv_original_size0(input)\n        x_original = self.conv_original_size1(x_original)\n\n        layer0 = self.layer0(input)\n        layer1 = self.layer1(layer0)\n        layer2 = self.layer2(layer1)\n        layer3 = self.layer3(layer2)\n        layer4 = self.layer4(layer3)\n\n        layer4 = self.layer4_1x1(layer4)\n        x = self.upsample(layer4)\n        layer3 = self.layer3_1x1(layer3)\n        x = torch.cat([x, layer3], dim=1)\n        x = self.conv_up3(x)\n\n        x = self.upsample(x)\n        layer2 = self.layer2_1x1(layer2)\n        x = torch.cat([x, layer2], dim=1)\n        x = self.conv_up2(x)\n\n        x = self.upsample(x)\n        layer1 = self.layer1_1x1(layer1)\n        x = torch.cat([x, layer1], dim=1)\n        x = self.conv_up1(x)\n\n        x = self.upsample(x)\n        layer0 = self.layer0_1x1(layer0)\n        x = torch.cat([x, layer0], dim=1)\n        x = self.conv_up0(x)\n\n        x = self.upsample(x)\n        x = torch.cat([x, x_original], dim=1)\n        x = self.conv_original_size2(x)\n\n        out = self.conv_last(x)\n\n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_loss(pred, target):\n    smooth = 1.\n\n    # have to use contiguous since they may from a torch.view op\n    iflat = pred.contiguous().view(-1)\n    tflat = target.contiguous().view(-1)\n    intersection = (iflat * tflat).sum()\n\n    A_sum = torch.sum(iflat * iflat)\n    B_sum = torch.sum(tflat * tflat)\n    \n    return 1 - ((2. * intersection + smooth) / (A_sum + B_sum + smooth) )\n\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_seg = ResNetUNet(n_class=1)\nmodel_seg=model_seg.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class my_sigmoid_layer(nn.Module):\n    def __init__(self,):\n        super(my_sigmoid_layer,self).__init__()\n    def forward(self,input):\n        return F.sigmoid(input) \n    \nlast_layer=my_sigmoid_layer()   \nmodel_seg = nn.Sequential(model_seg,last_layer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Train_dataset_seg(Dataset):\n    def __init__(self,csv_path,transform_img,transform_target):\n        self.data=pd.read_csv(csv_path)\n        self.train_data=self.data[self.data.name.str.match('train*')]\n        self.transform_img=transform_img\n        self.transform_target=transform_target\n    def __len__(self):\n        return len(self.train_data)\n\n    def __getitem__(self,index):\n        image_name=self.train_data.name.iloc[index]\n        image=Image.open(image_name+'.bmp')\n        image=self.transform_img(image)\n        label=Image.open(image_name+'_anno.bmp')\n        label=self.transform_target(label)\n        t = torch.Tensor([0]) # threshold\n        out = (label > t).float() * 1\n        return [image,out]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Valid_dataset_seg(Dataset):\n    def __init__(self,csv_path,transform_img,transform_target):\n        self.data=pd.read_csv(csv_path)\n        self.train_data=self.data[self.data.name.str.match('testA*')]\n        self.transform_img=transform_img\n        self.transform_target=transform_target\n    def __len__(self):\n        return len(self.train_data)\n\n    def __getitem__(self,index):\n        image_name=self.train_data.name.iloc[index]\n        image=Image.open(image_name+'.bmp')\n        image=self.transform_img(image)\n        label=Image.open(image_name+'_anno.bmp')\n        label=self.transform_target(label)\n        t = torch.Tensor([0])  # threshold\n        out = (label > t).float() * 1\n        return [image,out]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform_img=transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n])\ntransform_target=transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset=Train_dataset_seg('Grade.csv',transform_img,transform_target)\nvalid_dataset=Valid_dataset_seg('Grade.csv',transform_img,transform_target)\n\nparams = {'batch_size': 2,'shuffle': True}\n\ntraining_generator = DataLoader(train_dataset, **params)\nvalid_generator = DataLoader(valid_dataset, **params)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install torchsummary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchsummary import summary\nsummary(model_seg, input_size=(3, 224, 224))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model_seg(model, dataloaders, criterion, optimizer, num_epochs=25):\n    since = time.time()\n\n    val_loss_history = []\n    train_loss_history= []\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_loss_so_far = 9999999999\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train','val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    #outputs=F.log_softmax(outputs)\n                    outputs = m(outputs)\n                    bceLoss=nn.BCELoss()\n                    loss = criterion(outputs, labels)+bceLoss(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n\n            print('{} Loss: {:.4f} '.format(phase, loss))\n\n            # deep copy the model\n            if phase == 'val' and loss < best_loss_so_far:\n                best_loss_so_far=loss\n                best_model_wts = copy.deepcopy(model.state_dict())\n            if phase == 'val':\n                val_loss_history.append(loss)\n            if phase =='train':\n                with torch.no_grad(): \n                    train_loss_history.append(loss)\n                \n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print('Best loss in validation set : {:4f}'.format(best_loss_so_far))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, val_loss_history,train_loss_history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params_to_update = []\nfor name,param in model_seg.named_parameters():\n    if param.requires_grad == True:\n        params_to_update.append(param)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataloaders={'train':training_generator,'val':valid_generator}\noptimizer = optim.Adam(params_to_update,lr=1e-4)\ncriterion = dice_loss # + bce loss in model_seg loss calculation\nnum_epochs=50\nmodel_best,v_hist,t_hist=train_model_seg(model_seg, dataloaders, criterion, optimizer, num_epochs=num_epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor inputs, labels in valid_generator:\n    inputs=inputs.to(device)\n    \n    output=model_best(inputs).cpu()\n    #m = nn.Sigmoid()\n    #output = m(output)\n    #output=output*255\n    #t = torch.Tensor([0])  # threshold\n    #out = (output[0] > t).float() * 255\n    img = np.transpose(output[0], (1,2,0))\n    img=img.squeeze()\n    plt.imshow(img)\n    plt.show()\n    break\n\n#annotation on validation set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vhist = []\n\nvhist = [h.cpu().numpy() for h in v_hist]\nthist = []\n\nthist = [h.cpu().detach().numpy() for h in t_hist]\n\nplt.title(\"Loss vs. Number of Training Epochs\")\nplt.xlabel(\"Training Epochs\")\nplt.ylabel(\"Validation Loss\")\nplt.plot(range(1,num_epochs+1),vhist,label=\"Validation loss \")\nplt.plot(range(1,num_epochs+1),thist,label=\"Train loss\")\n\nplt.xticks(np.arange(1, num_epochs+1, 1.0))\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Image.open('testA_5.bmp')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#original annotation  for testA_5\nimage_name='testA_5_anno'\nimage=Image.open(image_name+'.bmp')\nlabel=transform_target(image)\nt = torch.Tensor([0])  # threshold\nout = (label > t).float() * 255\nimg = np.transpose(out, (1,2,0))\nimg=img.squeeze()\nplt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_name='testA_5'\nimage=Image.open(image_name+'.bmp')\nimage=transform_img(image)\nimage=image.unsqueeze(0)\nimage=image.to(device)\noutput=model_best(image)\noutput=output.cpu()\n#m = nn.Sigmoid()\n#output = m(output)\n#output=output*255\n#t = torch.Tensor([0])  # threshold\n#out = (output[0] > t).float() * 255\nimg = np.transpose(output[0], (1,2,0))\nimg=img.squeeze()\nplt.imshow(img)\nplt.show()\n#predicted testA_5 annotation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"test.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":1}